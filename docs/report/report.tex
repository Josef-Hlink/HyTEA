%%%%%%%% ICML 2021 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}
\usepackage{float}
\usepackage{microtype}
\bibliographystyle{icml2021}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs}
\usepackage{float}
\usepackage{gensymb}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}

\usepackage{url}
\def\UrlBreaks{\do\/\do-}
\usepackage{breakurl}
\usepackage[breaklinks]{hyperref}
\usepackage{hyperref}

\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\TODO}[1]{\textcolor{blue}{#1}}

\usepackage[accepted]{icml2021}

\icmltitlerunning{Hyperparameter Tuning using Evolutionary Algorithms}

\begin{document}

\twocolumn[
\icmltitle{Hyperparameter Tuning using Evolutionary Algorithms}
\icmlsetsymbol{equal}{*}
\begin{icmlauthorlist}
    \icmlauthor{T. Blom (sXXXXXXXX)}{LIACS}
    \icmlauthor{J. Hamelink (s2233827)}{LIACS}
    \icmlauthor{L. Peeters (s2011174)}{LIACS}
    \icmlauthor{S. Sharma (sXXXXXXX)}{LIACS}
\end{icmlauthorlist}
\icmlaffiliation{LIACS}{LIACS, Leiden University, Leiden, Netherlands}
\icmlcorrespondingauthor{Mike Preuss}{LIACS}
\icmlkeywords{Hyperparameter Tuning, Evolutionary Algorithms, Reinforcement Learning}

\vskip 0.3in
]

\printAffiliationsAndNotice{}

% -------------------------------------------------------------------
% -------------------------------------------------------------------
\section{Introduction}
\label{sec:intro}
Hyperparameter tuning is an active research topic in machine learning that can have a significant impact on the performance of models. 
The process of manually fine-tuning hyperparameters can be time-consuming. 
In this study, we propose the use of a genetic algorithm as a means to optimize the hyperparameters of an Advantage Actor-Critic (A2C) agent. 
This includes the hyperparameters of the neural network the agent uses such as the number of layers, the number of neurons per layer, the activation functions employed, and the learning rate. Furthermore, hyperparameters of the A2C agent such as the discount factor, Entropy Regularization, and baseline subtraction. 
We aim to automate the exploration of various hyperparameter settings using a genetic algorithm, with the goal of finding an optimal combination. 
We use a bitstring representation to encode and manipulate the hyperparameter configuration. 
Each bit or set of bits within the string corresponds to a specific hyperparameter setting, allowing for easy manipulation by the genetic algorithm's evolutionary process. 
Similar to the process of natural selection and genetics, the genetic algorithm starts with an initial population of bitstrings and iteratively tries to improve them with the goal of finding an optimal configuration of hyperparameters. 
To evaluate the performance and effectiveness of our Hyperparameter Optimization (HPO) algorithm for the A2C agent, we apply the agent on three of OpenAI's Gym environments: CartPole-v1, Acrobot-v1, and LunarLander-v2. 
These environments provide varying sizes of action and observation spaces, enabling a more generalized assessment of the HPO algorithm's performance.
In this study, we aim to investigate the impact of our genetic algorithm-based HPO approach on the performance and convergence speed of the A2C agent in various Gym environments. 

% -------------------------------------------------------------------
% -------------------------------------------------------------------
\section{Methodology}
\label{sec:meth}

\TODO{small intro for this section.}

% -------------------------------------------------------------------
\subsection{Actor-Critic}
\label{ssec:ac}

\TODO{
    We do A2C.
    Pseudo-code and equations.
    Explain methods: 2-headed neural network, entropy regularization, baseline subtraction, advantage estimation (calculating returns).
    Mention that these params will be tuned using EA.
}

We don't use this paper, but it's just to show that the citations work \cite{han2020actorcritic}.

% EXAMPLE ALGORITHM
\begin{algorithm}[htbp]
    \caption{Actor-Critic}
    \label{alg:trunk}
    \begin{algorithmic}[1]
        \STATE {\bfseries Input:} environment, $\pi_\theta$, $V_\phi$
        \STATE \texttt{$\pi_\theta$} $\gets$ random values
        \STATE \texttt{$V_\phi$} $\gets$ random values
        
        \WHILE {not converged}
            \STATE Under policy $\pi_\theta$,
            \STATE sample episode $s_0, a_0, r_1, \dots, s_{T-1}, a_{T-1}, r_T$
            \STATE \texttt{G} $\gets$ discounted returns using equation \ref{eq:disc-ret}
            \IF {baseline subtraction}
                \STATE \texttt{G} $\gets$ \texttt{G} - \texttt{V}
            \ELSE
                \STATE \texttt{G} $\gets$ \texttt{G}
            \ENDIF
            \STATE Update $\pi_\theta$ and $V_\phi$ using \texttt{G}
        \ENDWHILE
    \end{algorithmic}
\end{algorithm}

% EXAMPLE EQUATION
\begin{equation}
    \label{eq:disc-ret}
    G_t = \sum_{k=0}^{\infty} \gamma^k r_{t+k+1}
\end{equation}

% -------------------------------------------------------------------
\subsection{Evolutionary Algorithm} \label{ssec:EA}
\TODO{
    Maybe add some figures of crossover and stuff, but I'm not sure if that's necessary.
    
}

The hyperparameter configuration for the Actor-Critic network will be optimized using an Evolutionary Algorithm (EA) \cite{Simon2013EvolutionaryOA}. EA is a metaheuristic population-based algorithm that is inspired by biological evolution. Pseudocode for EA is presented in Algorithm \ref{alg:EA}.

\begin{algorithm}[htbp]
    \caption{Evolutionary Algorithm}
    \label{alg:EA}
    \begin{algorithmic}[1]
        \STATE population $\gets$ random values
        \STATE candidate $\gets$ None
        \STATE max$\_$fitness $\gets$ -$\infty$
        
        \FOR {$N_{generations}$}
            \STATE fitness $\gets$ evaluate population
            \IF {max(fitness) $>$ max$\_$fitness}
            	\STATE max$\_$fitness $\gets$ max(fitness)
            	\STATE candidate $\gets$ best individual
            \ENDIF
            \STATE Select $\mu$ candidates
            \STATE Generate offspring via crossover
            \STATE Mutate population
        \ENDFOR        
    \end{algorithmic}
\end{algorithm}


The initial population is generated randomly. After the population is created, the individuals are evaluated, in this case by using the hyperparameters corresponding to the individual to train the actor-critic network and evaluating it as described in section \ref{ssec:ac}. The resulting performence is called the individual's fitness value. 

Using the fitness values we select a subset $\mu$ of the population to reproduce, similar to how only fit individuals in a population in nature are able to find a mate. Selection is done greedily, which does not allow for any exploration of the search space and makes it is rather likely that the algorithm gets stuck in local minima. The greedy approach was chosen because of limited training resources. While the minimum found by a greedy approach might not be the best, it is found and explored quickly, allowing for a good proof of concept result. 

The selected individuals reproduce via a process known as crossover. Biologically, this refers to the crossing of chromosomes, leading to two new chromosomes that have part of the DNA of one parent, and part of the other. The algorithmic implementation of this process is very similar; take two selected parents and choose a random index where crossover occurs. One offspring gets the first part of parent 1 and the second part of parent 2, and another offspring gets the inverse. As such, each pair of two parents also creates two offspring. This process repeats until the set of offspring, named $\lambda$, is of the desired size. 

In nature each generation consists of only offspring. Parents continue to age, no matter how fit they are, and eventually become infertile and die. This is called a $(\mu, \lambda)$ process, where the parents are replaced by the offspring. Computer scientists have the luxury that the individuals do not age, so fit parents can be kept as long as is needed. This allows for a $(\mu+\lambda)$ algorithm, which is the form used in this paper. By allowing individuals to survive as long as they are fit enough, the algorithm can converge on a solution quicker. However, similar to the selection process, this sacrifices the ability to explore the search space. 

After creating offspring using crossover, the final step is mutation. In nature, genes can randomly be mutated through accidents during the replicating process or exposure to radiation. Generally, this is the main source of variation in biological populations. This project makes use of uniform mutation, where each bit of each individual has a small chance of being flipped. Mutation is the final step in creating a new generation, which can now be evaluated and go through the full process again. 

% EXAMPLE TABLE
\begin{table}[htbp]
    \centering
    \begin{tabular}
        {|c|c|}
        \toprule
        \textbf{Parameter} & \textbf{Value} \\
        \midrule
        population size & 6 \\
        $\mu$           & 3 \\
        $\lambda$       & 3 \\
        mutation rate   & 0.1 \\
        \bottomrule
    \end{tabular}
    \caption{Hyperparameters}
    \label{tab:hyper}
\end{table}

% -------------------------------------------------------------------
% -------------------------------------------------------------------
\section{Experiments}
\label{sec:exp}

\TODO{
    List environments: CartPole, Acrobot, LunarLander.
    Explain why these environments were chosen (discrete action space, no input that needs conv layers).
    List bitstring makeup: what values for what params.
    Don't mention results yet.
}

% -------------------------------------------------------------------
% -------------------------------------------------------------------
\section{Results}
\label{sec:res}

\TODO{
    For each of the subsections, small introduction of what is to be expected.
    Then graphs and tables.
    Then (not super in-depth) analysis of the results.
}

% -------------------------------------------------------------------
\subsection{CartPole}
\label{ssec:cp}

\TODO{Lorem ipsum.}

% EXAMPLE FIGURE
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth]{figs/lc-cp.png}
    \caption{
        Be descriptive of what different colors/lines mean.
        A multi-line caption should be formatted as such.
        Try to not exceed 3 lines.
    }
    \label{fig:lc-cp}
\end{figure}

% -------------------------------------------------------------------
\subsection{Acrobot}
\label{ssec:ab}

\TODO{Lorem ipsum.}

% -------------------------------------------------------------------
\subsection{LunarLander}
\label{ssec:ll}

\TODO{Lorem ipsum.}

% -------------------------------------------------------------------
% -------------------------------------------------------------------
\section{Conclusion}
\label{sec:conc}

\TODO{
    What did we find, why are some architectures/params better than others for specific environment?
    Is EA a valid approach for this problem?
}

\section{Discussion}
\label{sec:disc}

\TODO{
    What could be improved?
    What could be done differently?
    What could be done next?
}

% -------------------------------------------------------------------
\bibliography{references}

\end{document}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hytea.utils import DotDict\n",
    "\n",
    "from pathlib import Path\n",
    "from yaml import safe_load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path() / 'hytea' / 'config.yaml', 'r') as f:\n",
    "    CFG = DotDict.from_dict(safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path() / 'results' / 'data'\n",
    "PLOTS = Path() / 'results' / 'plots'\n",
    "\n",
    "PLOTS.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\" Get both dataframes for a given experiment name.\n",
    "\n",
    "    First merges all training csv files into one dataframe.\n",
    "    Then merges all summary csv files into one dataframe.\n",
    "    Finally, returns both dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    # check how many csv files there are for this experiment\n",
    "    n = len(list(DATA.glob(f'{name}*tr.csv')))\n",
    "    trdfs = []\n",
    "    for i in range(1, n+1):\n",
    "        trdfs.append(pd.read_csv(DATA / f'{name}{i}tr.csv', index_col=0))\n",
    "\n",
    "    trdf = pd.concat(trdfs, axis=1)\n",
    "    # filter out columns with __MIN in the name\n",
    "    trdf = trdf.loc[:, ~trdf.columns.str.contains('__MIN')]\n",
    "    # filter out columns with __MAX in the name\n",
    "    trdf = trdf.loc[:, ~trdf.columns.str.contains('__MAX')]\n",
    "\n",
    "    # remove \" - train_reward\" from the column names\n",
    "    trdf.columns = trdf.columns.str.replace(' - train_reward', '')\n",
    "\n",
    "    # transpose the dataframe\n",
    "    trdf = trdf.T\n",
    "    trdf.index.name = 'runID'\n",
    "\n",
    "    sdfs = []\n",
    "    for i in range(1, n+1):\n",
    "        sdfs.append(pd.read_csv(DATA / f'{name}{i}s.csv', index_col=0))\n",
    "    \n",
    "    sdf = pd.concat(sdfs, axis=0)\n",
    "\n",
    "    # create df with only the columns we are interested in\n",
    "    sdf = sdf.loc[:, ['agent.bl_sub', 'agent.ent_reg_weight', 'agent.gamma', 'group_name', 'network.hidden_activation', 'network.hidden_size', 'network.num_layers', 'optimizer.lr', 'optimizer.lr_decay', 'optimizer.lr_step', 'test_reward']]\n",
    "\n",
    "    sdf.index.name = 'runID'\n",
    "\n",
    "    return trdf, sdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to plot global rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(\n",
    "    grouper: pd.Grouper, df_tr: pd.DataFrame, df_s: pd.DataFrame,\n",
    "    title: str, max: bool = False\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot the rewards on a global episode scale.\n",
    "    If max is True, the maximum reward is plotted instead of the mean.\n",
    "    \"\"\"\n",
    "\n",
    "    dfs: list[pd.DataFrame] = []\n",
    "    for name in grouper.groups.keys():\n",
    "        dfs.append(df_tr.loc[df_s.loc[df_s['group_name'] == name].index])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    l = dfs[0].shape[1]\n",
    "\n",
    "    test_points = []\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        data = df.mean(axis=0) if not max else df.max(axis=0)\n",
    "        smooth_data = savgol_filter(data, 51, 3)\n",
    "        ax.plot(np.arange(i*l+1, (i+1)*l+1), data, alpha=0.5, color='tab:blue', zorder=1)\n",
    "        ax.plot(np.arange(i*l+1, (i+1)*l+1), smooth_data, color='tab:blue', zorder=2)\n",
    "\n",
    "        # take average/max test reward\n",
    "        test_rewards = df_s.loc[df.index, 'test_reward']\n",
    "        data_point = test_rewards.mean() if not max else test_rewards.max()\n",
    "        ax.scatter((i+1)*l, data_point, color='tab:red', marker='x', s=100, zorder=4)\n",
    "        test_points.append(data_point)\n",
    "\n",
    "    # plot the average/max test reward\n",
    "    smoothed_test_points = savgol_filter(test_points, 5, 2)\n",
    "    ax.plot(np.arange(1, len(test_points)+1)*l, smoothed_test_points, linestyle='--', color='tab:red', zorder=3)\n",
    "\n",
    "    ax.set_xlabel('global episode')\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "    ax.xaxis.set_major_formatter(lambda x, pos: f'{x/1000:.1f}k')\n",
    "\n",
    "    ax.legend(handles=[\n",
    "        plt.Line2D([0], [0], color='tab:blue', label='train reward'),\n",
    "        plt.Line2D([0], [0], color='tab:red', label='test reward'),\n",
    "    ])\n",
    "\n",
    "    ax.set_ylabel('avg. reward' if not max else 'max. reward')\n",
    "    ax.set_title(title + (' (max)' if max else ' (avg)'))\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {}\n",
    "for name in ['ab', 'cp', 'll']:\n",
    "    trdf, sdf = load_data(name)\n",
    "    db[name] = {'tr': trdf, 's': sdf}\n",
    "\n",
    "DB: DotDict[str, DotDict[str, pd.DataFrame]] = DotDict.from_dict(db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot global rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_rewards(DB.ab.s.groupby('group_name'), DB.ab.tr, DB.ab.s, 'AcroBot-v1')\n",
    "fig.savefig(PLOTS / 'ab_avg_rewards.png', dpi=500)\n",
    "\n",
    "fig = plot_rewards(DB.cp.s.groupby('group_name'), DB.cp.tr, DB.cp.s, 'CartPole-v1')\n",
    "fig.savefig(PLOTS / 'cp_avg_rewards.png', dpi=500)\n",
    "\n",
    "fig = plot_rewards(DB.ll.s.groupby('group_name'), DB.ll.tr, DB.ll.s, 'LunarLander-v2')\n",
    "fig.savefig(PLOTS / 'll_avg_rewards.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_rewards(DB.ab.s.groupby('group_name'), DB.ab.tr, DB.ab.s, 'AcroBot-v1', max=True)\n",
    "fig.savefig(PLOTS / 'ab_max_rewards.png', dpi=500)\n",
    "\n",
    "fig = plot_rewards(DB.cp.s.groupby('group_name'), DB.cp.tr, DB.cp.s, 'CartPole-v1', max=True)\n",
    "fig.savefig(PLOTS / 'cp_max_rewards.png', dpi=500)\n",
    "\n",
    "fig = plot_rewards(DB.ll.s.groupby('group_name'), DB.ll.tr, DB.ll.s, 'LunarLander-v2', max=True)\n",
    "fig.savefig(PLOTS / 'll_max_rewards.png', dpi=500)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore population diversity per generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_occurrences_table(grouper: pd.Grouper, caption: str, label: str) -> None:    \n",
    "    relevant_columns = [name for name in grouper.get_group('Gen1').columns if name not in ['test_reward', 'group_name']]\n",
    "\n",
    "    df = pd.DataFrame(columns=relevant_columns)\n",
    "    df.index.name = 'generation'\n",
    "\n",
    "    occurences = []\n",
    "\n",
    "    for _, group in grouper:\n",
    "        # calculate the number of occurences each hyperparameter setting is present in the group\n",
    "        occ = {param: {setting: 0 for setting in group[param].unique()} for param in relevant_columns}\n",
    "        for _, row in group.iterrows():\n",
    "            for param in relevant_columns:\n",
    "                occ[param][row[param]] += 1\n",
    "        occurences.append(occ)\n",
    "    \n",
    "    tab = '    '\n",
    "\n",
    "    print(r'\\begin{table*}[htbp]')\n",
    "    print(tab + r'\\centering')\n",
    "    print(tab + r'\\begin{tabular}')\n",
    "    print(tab * 2 + r'{|c|' + 'c' * len(grouper) + '|}')\n",
    "    print(tab * 2 + r'\\toprule')\n",
    "    print(tab * 2 + r'\\textbf{param - value} & ' + ' & '.join([f'\\\\textbf{{{gen}}}' for gen in range(1, len(grouper)+1)]) + r'\\\\')\n",
    "    print(tab * 2 + r'\\midrule')\n",
    "    # loop over occureneces with keys that start with 'agent.'\n",
    "    for param in relevant_columns:\n",
    "        for val in eval(f'CFG.{param}.vals'):\n",
    "            parsed_param = param.replace('_', ' ').replace('agent.', '').replace('network.', '').replace('optimizer.', '').replace('hidden ', '')\n",
    "            print(tab * 2 + f'{parsed_param} - {val}', end=' ')\n",
    "            for i in range(len(grouper)):\n",
    "                try:\n",
    "                    print(f'& {occurences[i][param][val] // 2}', end=' ')\n",
    "                except KeyError:\n",
    "                    print(f'& {0}', end=' ')\n",
    "            print(r'\\\\')\n",
    "        print(tab * 2 + r'\\midrule')\n",
    "    print(tab * 2 + r'\\bottomrule')\n",
    "    print(tab + r'\\end{tabular}')\n",
    "    print(tab + rf'\\caption{{{caption}}}')\n",
    "    print(tab + rf'\\label{{{label}}}')\n",
    "    print(r'\\end{table*}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_occurrences_table(DB.ab.s.groupby('group_name'), 'AcroBot-v1', 'tab:ab_occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_occurrences_table(DB.cp.s.groupby('group_name'), 'CartPole-v1', 'tab:cp_occ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_occurrences_table(DB.ll.s.groupby('group_name'), 'LunarLander-v2', 'tab:ll_occ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
